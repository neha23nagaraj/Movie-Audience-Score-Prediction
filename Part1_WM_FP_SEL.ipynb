{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UzvnzU1DDTXUiNlLs5Q75EZDtvZMcKdD",
      "authorship_tag": "ABX9TyNCpYxtlVF2tLezHHiLh0FU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neha23nagaraj/Movie-Audience-Score-Prediction/blob/main/Part1_WM_FP_SEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j82vf9FWWjyy",
        "outputId": "8c8760e0-0ed1-4497-b2fd-0bab21c2b77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.31.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.4.0)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.4.26)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n",
            "Downloading selenium-4.31.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.31.0 trio-0.30.0 trio-websocket-0.12.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VJ5JfXGRVyK",
        "outputId": "f89d50d0-07c6-4a71-a284-a566f67b4568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6o6mtUNWhXp",
        "outputId": "1ce57b7f-1543-487c-ae95-9064ed8f436d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Movies: 100%|██████████| 500/500 [2:06:42<00:00, 15.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Done! Data saved to rottentomatoes_movies.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_movie_data_selenium(url):\n",
        "    options = Options()\n",
        "    options.add_argument(\"--headless\")\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    driver.get(url)\n",
        "    time.sleep(5)  # Wait for JS content\n",
        "\n",
        "    movie = {}\n",
        "\n",
        "    # Title\n",
        "    try:\n",
        "        title_element = driver.find_element(By.CSS_SELECTOR, 'rt-text[slot=\"title\"]')\n",
        "        movie['Title'] = title_element.text.strip()\n",
        "    except:\n",
        "        movie['Title'] = None\n",
        "\n",
        "    # Rating, Release Date, Duration\n",
        "    try:\n",
        "      meta_props = driver.find_elements(By.CSS_SELECTOR, 'rt-text[slot=\"metadataProp\"]')\n",
        "\n",
        "      # Extract their text content by order\n",
        "      if len(meta_props) >= 3:\n",
        "         movie['Rating'] = meta_props[0].text.strip().replace(\",\", \"\").strip()\n",
        "         movie['Release Date'] = meta_props[1].text.strip().replace(\"Released\", \"\").strip().rstrip(',')\n",
        "         movie['Duration'] = meta_props[2].text.strip().replace(\",\", \"\").strip()\n",
        "      else:\n",
        "         movie['Rating'] = movie['Release Date'] = movie['Duration'] = None\n",
        "    except:\n",
        "        movie['Rating'] = movie['Release Date'] = movie['Duration'] = None\n",
        "\n",
        "    # Extract Directors (those with \"Director\" in aria-label)\n",
        "    try:\n",
        "        director_elements = driver.find_elements(By.CSS_SELECTOR, 'a[data-qa=\"person-item\"] div[slot=\"insetText\"]')\n",
        "        directors = [el.get_attribute(\"aria-label\").split(\",\")[0]\n",
        "                 for el in director_elements\n",
        "                 if \"Director\" in el.get_attribute(\"aria-label\")]\n",
        "        movie['Director'] = \", \".join(directors)\n",
        "    except:\n",
        "        movie['Director'] = None\n",
        "\n",
        "    # Cast (inside shadow DOM-ish structure)\n",
        "    try:\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(3)\n",
        "        cast_elements = driver.find_elements(By.CSS_SELECTOR, 'a[data-qa=\"person-item\"] div[slot=\"insetText\"]')\n",
        "\n",
        "        cast = [el.get_attribute(\"aria-label\").split(\",\")[0]\n",
        "            for el in cast_elements\n",
        "            if \"Director\" not in el.get_attribute(\"aria-label\")]\n",
        "\n",
        "        movie['Cast'] = \", \".join(cast)\n",
        "    except:\n",
        "        movie['Cast'] = None\n",
        "\n",
        "    # Synopsis\n",
        "    try:\n",
        "        synopsis_element = driver.find_element(By.CSS_SELECTOR, 'rt-text[slot=\"content\"]')\n",
        "        movie['Synopsis'] = synopsis_element.text.strip()\n",
        "    except:\n",
        "        movie['Synopsis'] = None\n",
        "\n",
        "    # --- Extract Genre ---\n",
        "    try:\n",
        "        genre_elements = driver.find_elements(By.CSS_SELECTOR, 'rt-text[slot=\"metadataGenre\"]')\n",
        "        genres = [g.text.strip() for g in genre_elements]\n",
        "        movie['Genre'] = \", \".join(genres)  # Join multiple genres into one string\n",
        "    except:\n",
        "        movie['Genre'] = None\n",
        "\n",
        "    # Critic Score (as %)\n",
        "    try:\n",
        "        cs = driver.find_element(By.CSS_SELECTOR, 'rt-text[slot=\"criticsScore\"]').text.strip()\n",
        "        movie['Critic_Score'] = float(cs.replace('%', '')) if cs else None\n",
        "    except:\n",
        "        movie['Critic_Score'] = None\n",
        "\n",
        "    # Critic Review Count\n",
        "    try:\n",
        "        cr = driver.find_element(By.CSS_SELECTOR, 'rt-link[slot=\"criticsReviews\"]').text.strip()\n",
        "        movie['Critic_Review_Count'] = int(re.search(r'\\d+', cr).group()) if cr else None\n",
        "    except:\n",
        "        movie['Critic_Review_Count'] = None\n",
        "\n",
        "    # Audience Review Count\n",
        "    try:\n",
        "        ar = driver.find_element(By.CSS_SELECTOR, 'rt-link[slot=\"audienceReviews\"]').text.strip()\n",
        "        movie['Audience_Review_Count'] = int(re.search(r'\\d+', ar).group()) if ar else None\n",
        "    except:\n",
        "        movie['Audience_Review_Count'] = None\n",
        "\n",
        "    # Audience Score\n",
        "    try:\n",
        "        score = driver.find_element(By.CSS_SELECTOR, 'rt-text[slot=\"audienceScore\"]').text.strip().replace('%', '')\n",
        "        movie['Audience Score'] = int(score)\n",
        "    except:\n",
        "        movie['Audience Score'] = None\n",
        "\n",
        "    driver.quit()\n",
        "    return movie\n",
        "\n",
        "# Read the CSV file with movie URLs\n",
        "input_csv = \"/content/drive/MyDrive/WebMining/rottentomatoes_500_movies_by_genre.csv\"\n",
        "df_urls = pd.read_csv(input_csv)\n",
        "\n",
        "# Extract URLs from the column (assumes column name is 'url')\n",
        "movie_urls = df_urls['url'].dropna().tolist()\n",
        "\n",
        "# Placeholder for movie metadata\n",
        "all_movies = []\n",
        "\n",
        "# Loop through URLs and scrape\n",
        "for url in tqdm(movie_urls, desc=\"Scraping Movies\"):\n",
        "    try:\n",
        "        movie_data = scrape_movie_data_selenium(url)  # Use your existing function\n",
        "        all_movies.append(movie_data)\n",
        "        time.sleep(1)  # Optional polite delay\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to scrape {url} -> {e}\")\n",
        "        continue\n",
        "\n",
        "# Convert to DataFrame and save\n",
        "df = pd.DataFrame(all_movies)\n",
        "df.to_csv(\"rottentomatoes_movies.csv\", index=False)\n",
        "print(\"\\n✅ Done! Data saved to rottentomatoes_movies.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('rottentomatoes_movies.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Bm5rkA3F9qET",
        "outputId": "ebcccc4f-8ea0-4ae2-80f2-adac33e3793b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ba3872e-5bfe-4f45-b130-18922e3ec2c0\", \"rottentomatoes_movies.csv\", 272154)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}